# -*- coding: utf-8 -*-
"""Lab_3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mSV_otkqyts_S0G9tlHe0_KbVFmokKkW
"""

import sqlite3
import requests
from bs4 import BeautifulSoup

#connector to SQL_Lab Database
connector = sqlite3.connect("./SQL_Lab.db")

#cursor to execute commands on database
cursor = connector.cursor()

#creates customers table
table1 = """ CREATE TABLE IF NOT EXISTS customers (
	 customer_id	INTEGER,
	customer_name	TEXT,
	customer_age	INTEGER,
	PRIMARY KEY( customer_id)
); """

#creates orders table
table2 = """CREATE TABLE IF NOT EXISTS "orders" (
	"order_id"	INTEGER,
	"customer_id"	INTEGER,
	"shippement_id"	INTEGER,
	"quantity"	INTEGER,
	PRIMARY KEY("order_id")
); """

#creates products table
table3 = """ CREATE TABLE IF NOT EXISTS "products" (
	"product_id"	INTEGER,
	"product_name"	TEXT,
	"product_category"	TEXT,
	PRIMARY KEY("product_id")
);"""

#creates customer sales table
table4 = """CREATE TABLE IF NOT EXISTS "sales" (
	"sales_id"	INTEGER,
	"product_id"	INTEGER,
	"sales_person_name"	TEXT,
	"sales_amount"	INTEGER,
	PRIMARY KEY("sales_id","sales_person_name")
);"""


cursor.execute(table1)
cursor.execute(table2)
cursor.execute(table3)
cursor.execute(table4)

sql = ''' INSERT INTO customers
            VALUES  (100, 'John Svedson', 35),
            (200, 'Stephen Adams', 25),
            (300, 'Kari Petterson', 45),
            (400, 'James McClure', 30)
            
            '''
sql1 = ''' INSERT INTO orders 
            VALUES (1000, 100,5000, 100),
            (1001, 400, 5050, 30),
            (1002, 100, 5100, 20),
            (1003, 200, 5500, 50),
            (1004, 200, 5350, 10),
            (1005, 300, 5450, 200)
      '''
sql2 = ''' INSERT INTO products 
            VALUES (12, 'Bike ABC', 'Road Bike'),
            (13, 'Bike DEF', 'Mountain Bike'),
            (14, 'Bike GHI', 'Road Bike'),
            (15, 'Bike JKL', 'Touring Bike')
        '''
sql3 = '''INSERT INTO sales 
            VALUES (10000, 12, 'Joe Brown', 1000),
            (10001, 12, 'Bill Johnson', 5000),
            (10002, 13, 'Joe Brown', 10000),
            (10003, 15, 'Bill Johnson', 3000)
          '''
cursor.execute(sql)
cursor.execute(sql1)
cursor.execute(sql2)
cursor.execute(sql3)
#queries all customers older than 30
cursor.execute('SELECT * FROM customers WHERE customer_age > 30;')
cursor.fetchall()
#returns customer name, order ID, and quanity of each purchase from the customer
cursor.execute('SELECT customer_name, order_id, quantity FROM customers, orders WHERE customers.customer_id = orders.customer_id')
cursor.fetchall()
#queries all distinct products categories
cursor.execute('SELECT DISTINCT product_category FROM products;')
cursor.fetchall()
#inner join connects products and sales table and queries sales person name, product name, sales amount, product category when product id is 12
cursor.execute('SELECT sales_person_name, product_name, sales_amount, product_category FROM products INNER JOIN sales ON sales.product_id = products.product_id WHERE sales.product_id = 12')
#updates sales id of 10000 sales person name to Sophia
cursor.execute('UPDATE sales SET sales_person_name = "Sophie Thomas" WHERE sales_id = 10000 ')
cursor.execute('SELECT * FROM sales')
cursor.fetchall()

#connect to api to retrieve a response frome API

resourceAPI = "https://api.datamuse.com/words?ml=ringing+in+the+ears&max=10"
response = requests.get(resourceAPI)

#take in input api

def queryAPI(inputAPI):
  print(response)
  print(response.content)
  print(response.headers)
  

#queryAPI(resourceAPI)
#program using BeautifulSoup to web scrape
url = "https://news.google.com" #website used to access news headlines
keywords = [' in ', 'Ukraine', 'Supreme', ' war ', 'Covid', 'covid', 'COVID'] #keywords for returning headlines
def headline_by_keywords(key): #headline by keyword method will take input of keywords and compare that to headlines of website
  j = 0
  val = {}
  response = requests.get(url)
  soup = BeautifulSoup(response.content,"html.parser")
  for i in soup.findAll('h4'): #finds all instances/headlines under h4
   val[j] = i.get_text() #creates val object with each instance of h4 read in through API
   j+=1    
  for items in val: #outer for loop to get val 
    for keys in keywords: #inner for loop to compare each keys in keyword with val
      if keys in val[items]:
        print(val[items])

headline_by_keywords(keywords) #prints headlines that contain words in keywords varialble